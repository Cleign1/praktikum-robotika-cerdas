{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nama     : Muhamad Ibnu Khaidar Hafiz\n",
        "### NPM     : 50421867\n",
        "### Kelas   : 4IA15\n",
        "### Praktikum Robotika cerdas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJp-D51g0IDd"
      },
      "source": [
        "## **1) Importing Python Packages for GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1k5mFBuzzl2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-26 15:13:03.395495: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-26 15:13:03.412796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-26 15:13:03.433633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-26 15:13:03.439998: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-26 15:13:03.454952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Import LeakyReLU directly from keras.layers\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "!mkdir generated_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-eZOzg0X79"
      },
      "source": [
        "## **2) Parameters for Neural Networks & Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RThZMDruz9cB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-26 15:13:07.432561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20750 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "img_width = 32\n",
        "img_height = 32\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 100\n",
        "adam = Adam(learning_rate=0.0002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3bcJZZg0cqy"
      },
      "source": [
        "## **3) Building Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NdiqZpri0iQh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">413,696</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,459</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │       \u001b[38;5;34m413,696\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m524,416\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m3,459\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create first layer, to receive the input\n",
        "    model.add(Dense(256 * 4 * 4, input_dim = latent_dim))\n",
        "    # 256 * 8 * 8; for upscaling the layers,\n",
        "    # initial shape to construct into final shape\n",
        "\n",
        "    # Create default activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    # Create reshape layer\n",
        "    model.add(Reshape((4, 4,256)))\n",
        "    # 8,8,256 ; reffers to first layer\n",
        "\n",
        "    # Adding more layers for neurons and better result\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    # (4,4) >> filter size\n",
        "    # strides = (2,2) >> Convolutional layers, that how NN understand images\n",
        "\n",
        "    # Create Final output layer and forming image shape\n",
        "    # the shape (3, (3,3)) reffers to image shape :\n",
        "    #    >>>  img_shape = (img_width, img_height, channels)\n",
        "    model.add(Conv2D(3, (3,3), activation= 'tanh', padding = 'same'))\n",
        "\n",
        "    #\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6QsJCW0mcI"
      },
      "source": [
        "## **4) Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V2JzEAPv0lKt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,145</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m262,145\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create input layer and filter and stride layer. That makes NN understand image\n",
        "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = img_shape))\n",
        "\n",
        "    # Adding activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(256, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Create output layer\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcKcKmA0q2S"
      },
      "source": [
        "## **5) Connecting Neural Networks to build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q0Ue3TEd0xLy"
      },
      "outputs": [],
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "EPqU8dZDaQmE",
        "outputId": "63dbba4f-bd86-4676-8c6e-f6966993c13d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │     \u001b[38;5;34m1,466,115\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m780,545\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,246,660</span> (8.57 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,246,660\u001b[0m (8.57 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "GAN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaNhBDwRwTG"
      },
      "source": [
        "## **6) Outputting Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HQEJ0WbjRppy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "    # print(\"%.8f\" % save_name)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "    # gen_imgs = gen_imgs * 255\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE57Lk5V0xs2"
      },
      "source": [
        "## **7) Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LJc1MkJV7OVr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1729955590.350439   64947 service.cc:146] XLA service 0x7fd8d4006160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1729955590.350470   64947 service.cc:154]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
            "2024-10-26 15:13:10.361985: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-10-26 15:13:10.399004: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8904\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1729955591.087149   64947 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******* 0 [D loss: 0.717884, acc: 27.34%] [G loss: 0.709294]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7fd9b4508dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7fd9b469f5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "******* 0 [D loss: 0.711143, acc: 39.19%] [G loss: 0.708559]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.710610, acc: 32.32%] [G loss: 0.709079]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.710858, acc: 25.11%] [G loss: 0.709760]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.710918, acc: 20.29%] [G loss: 0.710092]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.710814, acc: 16.88%] [G loss: 0.710181]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.710756, acc: 14.84%] [G loss: 0.710263]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "******* 0 [D loss: 0.711176, acc: 13.22%] [G loss: 0.710789]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.711534, acc: 11.71%] [G loss: 0.711230]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.711983, acc: 10.74%] [G loss: 0.711770]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.712245, acc: 9.74%] [G loss: 0.712109]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.712851, acc: 8.98%] [G loss: 0.712791]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.713394, acc: 8.34%] [G loss: 0.713421]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.713976, acc: 8.07%] [G loss: 0.714098]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.714786, acc: 7.89%] [G loss: 0.714990]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.715949, acc: 7.44%] [G loss: 0.716270]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.717010, acc: 7.14%] [G loss: 0.717444]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.718359, acc: 6.82%] [G loss: 0.718884]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.719761, acc: 6.46%] [G loss: 0.720397]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.721369, acc: 6.13%] [G loss: 0.722118]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.723086, acc: 5.99%] [G loss: 0.723987]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.725079, acc: 5.82%] [G loss: 0.726045]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.727253, acc: 5.70%] [G loss: 0.728367]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.729589, acc: 5.59%] [G loss: 0.730799]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.732027, acc: 5.37%] [G loss: 0.733302]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.734619, acc: 5.25%] [G loss: 0.736033]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.737366, acc: 5.11%] [G loss: 0.738822]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.740177, acc: 4.98%] [G loss: 0.741675]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.742936, acc: 4.86%] [G loss: 0.744491]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.745787, acc: 4.70%] [G loss: 0.747338]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.748707, acc: 4.65%] [G loss: 0.750326]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.751586, acc: 4.63%] [G loss: 0.753234]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.754537, acc: 4.53%] [G loss: 0.756156]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.757335, acc: 4.54%] [G loss: 0.758992]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.760166, acc: 4.45%] [G loss: 0.761798]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.762916, acc: 4.37%] [G loss: 0.764536]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.765601, acc: 4.38%] [G loss: 0.767191]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.768247, acc: 4.33%] [G loss: 0.769844]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.770832, acc: 4.25%] [G loss: 0.772394]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.773427, acc: 4.15%] [G loss: 0.774992]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.775971, acc: 4.10%] [G loss: 0.777552]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.778412, acc: 4.02%] [G loss: 0.779903]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.780800, acc: 3.95%] [G loss: 0.782313]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.783157, acc: 3.88%] [G loss: 0.784627]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.785535, acc: 3.86%] [G loss: 0.787071]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.787887, acc: 3.84%] [G loss: 0.789412]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.790236, acc: 3.81%] [G loss: 0.791711]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.792514, acc: 3.80%] [G loss: 0.794011]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.794877, acc: 3.77%] [G loss: 0.796369]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.797092, acc: 3.75%] [G loss: 0.798540]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.799253, acc: 3.74%] [G loss: 0.800673]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.801376, acc: 3.74%] [G loss: 0.802806]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.803575, acc: 3.70%] [G loss: 0.805030]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.805701, acc: 3.68%] [G loss: 0.807123]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.807811, acc: 3.64%] [G loss: 0.809172]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.809884, acc: 3.59%] [G loss: 0.811313]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.811962, acc: 3.55%] [G loss: 0.813325]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.814023, acc: 3.50%] [G loss: 0.815398]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.816012, acc: 3.48%] [G loss: 0.817380]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.817937, acc: 3.50%] [G loss: 0.819275]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.819852, acc: 3.49%] [G loss: 0.821198]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.821753, acc: 3.49%] [G loss: 0.823093]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.823681, acc: 3.47%] [G loss: 0.824998]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.825538, acc: 3.46%] [G loss: 0.826824]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.827328, acc: 3.47%] [G loss: 0.828644]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.829172, acc: 3.46%] [G loss: 0.830489]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.831037, acc: 3.44%] [G loss: 0.832346]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.832845, acc: 3.40%] [G loss: 0.834114]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.834630, acc: 3.40%] [G loss: 0.835910]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.836372, acc: 3.39%] [G loss: 0.837614]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.838106, acc: 3.35%] [G loss: 0.839361]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.839845, acc: 3.33%] [G loss: 0.841098]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.841558, acc: 3.33%] [G loss: 0.842808]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.843222, acc: 3.32%] [G loss: 0.844429]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.844852, acc: 3.34%] [G loss: 0.846074]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.846459, acc: 3.34%] [G loss: 0.847684]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.848141, acc: 3.32%] [G loss: 0.849361]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.849765, acc: 3.32%] [G loss: 0.850951]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.851365, acc: 3.31%] [G loss: 0.852575]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.852992, acc: 3.29%] [G loss: 0.854174]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.854558, acc: 3.26%] [G loss: 0.855731]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.856104, acc: 3.26%] [G loss: 0.857258]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.857646, acc: 3.25%] [G loss: 0.858791]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "******* 0 [D loss: 0.859161, acc: 3.21%] [G loss: 0.860298]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.860652, acc: 3.18%] [G loss: 0.861771]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.862094, acc: 3.17%] [G loss: 0.863201]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.863526, acc: 3.15%] [G loss: 0.864632]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.864941, acc: 3.14%] [G loss: 0.866042]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.866335, acc: 3.13%] [G loss: 0.867415]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.867712, acc: 3.15%] [G loss: 0.868801]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.869128, acc: 3.15%] [G loss: 0.870246]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.870538, acc: 3.13%] [G loss: 0.871606]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.871894, acc: 3.10%] [G loss: 0.872965]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.873226, acc: 3.09%] [G loss: 0.874271]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.874511, acc: 3.07%] [G loss: 0.875541]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.875781, acc: 3.08%] [G loss: 0.876818]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.877082, acc: 3.08%] [G loss: 0.878113]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.878369, acc: 3.06%] [G loss: 0.879410]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.879642, acc: 3.08%] [G loss: 0.880671]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.880920, acc: 3.05%] [G loss: 0.881961]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.882195, acc: 3.05%] [G loss: 0.883203]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.883479, acc: 3.04%] [G loss: 0.884495]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.884738, acc: 3.03%] [G loss: 0.885720]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.885937, acc: 3.02%] [G loss: 0.886915]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.887085, acc: 3.01%] [G loss: 0.888044]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.888271, acc: 3.00%] [G loss: 0.889261]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.889479, acc: 2.99%] [G loss: 0.890473]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.890723, acc: 2.98%] [G loss: 0.891715]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.891938, acc: 2.96%] [G loss: 0.892913]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.893110, acc: 2.98%] [G loss: 0.894061]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.894244, acc: 2.96%] [G loss: 0.895184]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.895361, acc: 2.96%] [G loss: 0.896290]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.896537, acc: 2.94%] [G loss: 0.897494]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.897691, acc: 2.92%] [G loss: 0.898625]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.898776, acc: 2.91%] [G loss: 0.899705]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.899925, acc: 2.91%] [G loss: 0.900859]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.901005, acc: 2.90%] [G loss: 0.901895]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.902070, acc: 2.89%] [G loss: 0.902978]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.903171, acc: 2.89%] [G loss: 0.904084]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.904255, acc: 2.87%] [G loss: 0.905172]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.905332, acc: 2.87%] [G loss: 0.906215]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.906370, acc: 2.87%] [G loss: 0.907260]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.907398, acc: 2.86%] [G loss: 0.908273]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.908432, acc: 2.84%] [G loss: 0.909301]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.909478, acc: 2.84%] [G loss: 0.910374]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.910525, acc: 2.83%] [G loss: 0.911396]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.911551, acc: 2.82%] [G loss: 0.912421]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.912555, acc: 2.79%] [G loss: 0.913404]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.913531, acc: 2.79%] [G loss: 0.914381]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.914495, acc: 2.78%] [G loss: 0.915334]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.915463, acc: 2.77%] [G loss: 0.916317]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.916421, acc: 2.78%] [G loss: 0.917252]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.917347, acc: 2.77%] [G loss: 0.918162]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.918252, acc: 2.75%] [G loss: 0.919058]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.919157, acc: 2.73%] [G loss: 0.919970]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.920069, acc: 2.71%] [G loss: 0.920876]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.920962, acc: 2.71%] [G loss: 0.921755]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.921848, acc: 2.69%] [G loss: 0.922636]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.922723, acc: 2.69%] [G loss: 0.923522]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.923604, acc: 2.68%] [G loss: 0.924378]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.924446, acc: 2.69%] [G loss: 0.925228]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.925322, acc: 2.68%] [G loss: 0.926112]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.926188, acc: 2.68%] [G loss: 0.926952]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.927045, acc: 2.66%] [G loss: 0.927833]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.927909, acc: 2.66%] [G loss: 0.928671]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.928734, acc: 2.65%] [G loss: 0.929494]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.929564, acc: 2.63%] [G loss: 0.930325]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.930390, acc: 2.65%] [G loss: 0.931140]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.931227, acc: 2.63%] [G loss: 0.931976]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.932025, acc: 2.63%] [G loss: 0.932768]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.932818, acc: 2.62%] [G loss: 0.933549]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.933631, acc: 2.61%] [G loss: 0.934377]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.934443, acc: 2.61%] [G loss: 0.935190]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.935272, acc: 2.60%] [G loss: 0.936015]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.936067, acc: 2.61%] [G loss: 0.936797]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.936851, acc: 2.60%] [G loss: 0.937590]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.937639, acc: 2.59%] [G loss: 0.938351]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.938400, acc: 2.59%] [G loss: 0.939120]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.939174, acc: 2.57%] [G loss: 0.939888]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.939927, acc: 2.56%] [G loss: 0.940630]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.940668, acc: 2.56%] [G loss: 0.941382]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.941428, acc: 2.56%] [G loss: 0.942138]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.942186, acc: 2.55%] [G loss: 0.942883]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.942926, acc: 2.57%] [G loss: 0.943639]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.943669, acc: 2.58%] [G loss: 0.944363]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.944402, acc: 2.57%] [G loss: 0.945095]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.945155, acc: 2.57%] [G loss: 0.945860]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.945882, acc: 2.58%] [G loss: 0.946564]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.946606, acc: 2.57%] [G loss: 0.947300]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.947320, acc: 2.56%] [G loss: 0.947985]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.948008, acc: 2.57%] [G loss: 0.948693]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.948740, acc: 2.57%] [G loss: 0.949425]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.949433, acc: 2.56%] [G loss: 0.950081]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.950107, acc: 2.54%] [G loss: 0.950776]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.950792, acc: 2.56%] [G loss: 0.951452]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.951456, acc: 2.56%] [G loss: 0.952111]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.952124, acc: 2.56%] [G loss: 0.952781]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.952812, acc: 2.56%] [G loss: 0.953470]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.953503, acc: 2.55%] [G loss: 0.954160]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.954192, acc: 2.54%] [G loss: 0.954843]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.954874, acc: 2.53%] [G loss: 0.955520]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.955536, acc: 2.53%] [G loss: 0.956169]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.956171, acc: 2.53%] [G loss: 0.956806]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.956817, acc: 2.52%] [G loss: 0.957463]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.957466, acc: 2.53%] [G loss: 0.958101]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.958105, acc: 2.52%] [G loss: 0.958742]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.958756, acc: 2.52%] [G loss: 0.959394]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.959394, acc: 2.53%] [G loss: 0.960012]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.960014, acc: 2.53%] [G loss: 0.960636]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.960633, acc: 2.52%] [G loss: 0.961256]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.961259, acc: 2.52%] [G loss: 0.961876]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.961879, acc: 2.52%] [G loss: 0.962489]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.962502, acc: 2.52%] [G loss: 0.963121]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.963140, acc: 2.52%] [G loss: 0.963757]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.963749, acc: 2.52%] [G loss: 0.964342]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.964331, acc: 2.53%] [G loss: 0.964933]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.964954, acc: 2.52%] [G loss: 0.965568]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.965571, acc: 2.52%] [G loss: 0.966173]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.966180, acc: 2.51%] [G loss: 0.966770]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.966752, acc: 2.50%] [G loss: 0.967331]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.967314, acc: 2.49%] [G loss: 0.967898]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.967895, acc: 2.49%] [G loss: 0.968469]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.968467, acc: 2.49%] [G loss: 0.969063]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.969055, acc: 2.48%] [G loss: 0.969636]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.969615, acc: 2.49%] [G loss: 0.970191]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.970172, acc: 2.49%] [G loss: 0.970742]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.970716, acc: 2.49%] [G loss: 0.971291]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.971280, acc: 2.48%] [G loss: 0.971854]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.971849, acc: 2.47%] [G loss: 0.972424]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.972405, acc: 2.48%] [G loss: 0.972972]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.972969, acc: 2.48%] [G loss: 0.973539]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.973530, acc: 2.48%] [G loss: 0.974105]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.974097, acc: 2.48%] [G loss: 0.974664]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.974640, acc: 2.48%] [G loss: 0.975202]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.975176, acc: 2.48%] [G loss: 0.975726]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.975694, acc: 2.48%] [G loss: 0.976240]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.976222, acc: 2.48%] [G loss: 0.976776]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.976758, acc: 2.48%] [G loss: 0.977309]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.977291, acc: 2.46%] [G loss: 0.977842]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.977817, acc: 2.46%] [G loss: 0.978361]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "******* 0 [D loss: 0.978346, acc: 2.46%] [G loss: 0.978891]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.978870, acc: 2.46%] [G loss: 0.979419]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.979400, acc: 2.45%] [G loss: 0.979953]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.979937, acc: 2.44%] [G loss: 0.980476]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.980457, acc: 2.44%] [G loss: 0.980987]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.980959, acc: 2.43%] [G loss: 0.981491]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.981465, acc: 2.43%] [G loss: 0.982001]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.981981, acc: 2.43%] [G loss: 0.982516]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.982497, acc: 2.42%] [G loss: 0.983028]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.982992, acc: 2.43%] [G loss: 0.983528]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.983510, acc: 2.42%] [G loss: 0.984041]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.984007, acc: 2.42%] [G loss: 0.984527]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.984498, acc: 2.43%] [G loss: 0.985024]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.984986, acc: 2.43%] [G loss: 0.985511]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.985483, acc: 2.43%] [G loss: 0.986001]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.985978, acc: 2.43%] [G loss: 0.986505]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.986486, acc: 2.43%] [G loss: 0.987011]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.986982, acc: 2.43%] [G loss: 0.987495]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.987453, acc: 2.44%] [G loss: 0.987967]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.987946, acc: 2.44%] [G loss: 0.988466]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.988435, acc: 2.44%] [G loss: 0.988944]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.988902, acc: 2.43%] [G loss: 0.989402]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.989362, acc: 2.43%] [G loss: 0.989860]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.989826, acc: 2.43%] [G loss: 0.990330]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.990295, acc: 2.43%] [G loss: 0.990791]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.990754, acc: 2.43%] [G loss: 0.991252]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.991206, acc: 2.43%] [G loss: 0.991695]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.991648, acc: 2.42%] [G loss: 0.992133]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.992085, acc: 2.43%] [G loss: 0.992570]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.992528, acc: 2.43%] [G loss: 0.993018]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.992969, acc: 2.43%] [G loss: 0.993450]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.993414, acc: 2.42%] [G loss: 0.993904]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.993864, acc: 2.42%] [G loss: 0.994349]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.994309, acc: 2.42%] [G loss: 0.994786]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.994740, acc: 2.42%] [G loss: 0.995222]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.995197, acc: 2.42%] [G loss: 0.995696]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.995667, acc: 2.42%] [G loss: 0.996149]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.996106, acc: 2.42%] [G loss: 0.996586]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.996527, acc: 2.42%] [G loss: 0.996995]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.996949, acc: 2.42%] [G loss: 0.997420]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.997374, acc: 2.41%] [G loss: 0.997849]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.997805, acc: 2.41%] [G loss: 0.998276]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.998218, acc: 2.41%] [G loss: 0.998677]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.998634, acc: 2.42%] [G loss: 0.999107]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.999065, acc: 2.42%] [G loss: 0.999536]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.999507, acc: 2.42%] [G loss: 0.999978]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 0.999926, acc: 2.42%] [G loss: 1.000384]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.000337, acc: 2.42%] [G loss: 1.000798]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.000738, acc: 2.42%] [G loss: 1.001189]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.001132, acc: 2.43%] [G loss: 1.001580]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.001522, acc: 2.43%] [G loss: 1.001974]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.001920, acc: 2.43%] [G loss: 1.002368]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.002314, acc: 2.42%] [G loss: 1.002761]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.002714, acc: 2.42%] [G loss: 1.003166]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.003117, acc: 2.42%] [G loss: 1.003571]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.003531, acc: 2.41%] [G loss: 1.003990]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.003930, acc: 2.41%] [G loss: 1.004377]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.004327, acc: 2.41%] [G loss: 1.004777]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.004709, acc: 2.41%] [G loss: 1.005144]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.005093, acc: 2.40%] [G loss: 1.005534]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.005480, acc: 2.40%] [G loss: 1.005922]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.005875, acc: 2.40%] [G loss: 1.006329]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.006273, acc: 2.40%] [G loss: 1.006711]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.006665, acc: 2.40%] [G loss: 1.007110]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.007050, acc: 2.41%] [G loss: 1.007485]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.007416, acc: 2.41%] [G loss: 1.007843]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.007792, acc: 2.41%] [G loss: 1.008230]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.008175, acc: 2.40%] [G loss: 1.008608]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.008558, acc: 2.39%] [G loss: 1.008994]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.008948, acc: 2.39%] [G loss: 1.009384]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.009335, acc: 2.39%] [G loss: 1.009769]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.009709, acc: 2.39%] [G loss: 1.010132]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.010066, acc: 2.39%] [G loss: 1.010489]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.010434, acc: 2.38%] [G loss: 1.010857]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.010794, acc: 2.39%] [G loss: 1.011213]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.011153, acc: 2.39%] [G loss: 1.011569]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.011526, acc: 2.38%] [G loss: 1.011951]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.011882, acc: 2.38%] [G loss: 1.012293]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.012238, acc: 2.37%] [G loss: 1.012658]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.012607, acc: 2.38%] [G loss: 1.013030]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.012961, acc: 2.38%] [G loss: 1.013374]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.013314, acc: 2.38%] [G loss: 1.013725]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.013669, acc: 2.37%] [G loss: 1.014080]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.014014, acc: 2.37%] [G loss: 1.014421]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.014361, acc: 2.37%] [G loss: 1.014770]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.014705, acc: 2.36%] [G loss: 1.015115]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "******* 0 [D loss: 1.015054, acc: 2.36%] [G loss: 1.015463]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.015399, acc: 2.36%] [G loss: 1.015801]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.015743, acc: 2.36%] [G loss: 1.016155]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.016094, acc: 2.36%] [G loss: 1.016496]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.016434, acc: 2.35%] [G loss: 1.016837]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.016774, acc: 2.35%] [G loss: 1.017173]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.017119, acc: 2.34%] [G loss: 1.017518]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.017451, acc: 2.34%] [G loss: 1.017851]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.017789, acc: 2.34%] [G loss: 1.018186]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.018116, acc: 2.33%] [G loss: 1.018515]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.018442, acc: 2.33%] [G loss: 1.018833]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.018776, acc: 2.33%] [G loss: 1.019164]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.019089, acc: 2.33%] [G loss: 1.019477]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.019423, acc: 2.32%] [G loss: 1.019819]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.019748, acc: 2.33%] [G loss: 1.020133]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.020062, acc: 2.32%] [G loss: 1.020451]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.020376, acc: 2.32%] [G loss: 1.020751]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.020701, acc: 2.32%] [G loss: 1.021095]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.021025, acc: 2.32%] [G loss: 1.021412]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.021349, acc: 2.32%] [G loss: 1.021732]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.021664, acc: 2.32%] [G loss: 1.022049]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.021986, acc: 2.32%] [G loss: 1.022368]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.022297, acc: 2.32%] [G loss: 1.022671]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.022601, acc: 2.31%] [G loss: 1.022979]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.022913, acc: 2.32%] [G loss: 1.023297]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.023224, acc: 2.32%] [G loss: 1.023603]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.023541, acc: 2.32%] [G loss: 1.023920]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.023849, acc: 2.32%] [G loss: 1.024223]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.024153, acc: 2.31%] [G loss: 1.024525]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.024458, acc: 2.31%] [G loss: 1.024836]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.024772, acc: 2.31%] [G loss: 1.025147]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.025079, acc: 2.30%] [G loss: 1.025447]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.025379, acc: 2.30%] [G loss: 1.025747]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.025676, acc: 2.30%] [G loss: 1.026043]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.025973, acc: 2.30%] [G loss: 1.026343]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.026269, acc: 2.29%] [G loss: 1.026637]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.026567, acc: 2.29%] [G loss: 1.026931]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.026854, acc: 2.29%] [G loss: 1.027215]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.027147, acc: 2.29%] [G loss: 1.027517]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.027454, acc: 2.28%] [G loss: 1.027825]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "******* 0 [D loss: 1.027745, acc: 2.28%] [G loss: 1.028104]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.028030, acc: 2.28%] [G loss: 1.028386]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.028306, acc: 2.28%] [G loss: 1.028661]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.028583, acc: 2.28%] [G loss: 1.028938]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.028864, acc: 2.28%] [G loss: 1.029221]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.029146, acc: 2.29%] [G loss: 1.029501]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.029429, acc: 2.29%] [G loss: 1.029781]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.029714, acc: 2.28%] [G loss: 1.030069]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.029987, acc: 2.28%] [G loss: 1.030336]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.030258, acc: 2.28%] [G loss: 1.030606]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.030525, acc: 2.28%] [G loss: 1.030871]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.030781, acc: 2.28%] [G loss: 1.031124]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.031046, acc: 2.28%] [G loss: 1.031399]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.031325, acc: 2.28%] [G loss: 1.031671]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.031595, acc: 2.28%] [G loss: 1.031942]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.031869, acc: 2.28%] [G loss: 1.032210]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.032134, acc: 2.29%] [G loss: 1.032481]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.032405, acc: 2.29%] [G loss: 1.032746]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.032678, acc: 2.28%] [G loss: 1.033020]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.032938, acc: 2.29%] [G loss: 1.033277]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.033199, acc: 2.30%] [G loss: 1.033540]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.033474, acc: 2.29%] [G loss: 1.033812]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.033746, acc: 2.29%] [G loss: 1.034082]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.033994, acc: 2.29%] [G loss: 1.034324]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.034244, acc: 2.29%] [G loss: 1.034582]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.034500, acc: 2.28%] [G loss: 1.034833]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.034756, acc: 2.28%] [G loss: 1.035092]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.035010, acc: 2.28%] [G loss: 1.035340]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.035263, acc: 2.28%] [G loss: 1.035593]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.035510, acc: 2.27%] [G loss: 1.035837]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.035752, acc: 2.28%] [G loss: 1.036079]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.035996, acc: 2.28%] [G loss: 1.036324]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.036245, acc: 2.27%] [G loss: 1.036572]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.036494, acc: 2.27%] [G loss: 1.036821]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.036740, acc: 2.27%] [G loss: 1.037065]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.036979, acc: 2.27%] [G loss: 1.037301]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.037220, acc: 2.27%] [G loss: 1.037544]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.037463, acc: 2.27%] [G loss: 1.037785]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.037706, acc: 2.27%] [G loss: 1.038028]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.037951, acc: 2.26%] [G loss: 1.038270]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.038194, acc: 2.26%] [G loss: 1.038515]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.038428, acc: 2.26%] [G loss: 1.038744]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.038663, acc: 2.26%] [G loss: 1.038980]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.038892, acc: 2.26%] [G loss: 1.039204]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.039125, acc: 2.26%] [G loss: 1.039445]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.039364, acc: 2.26%] [G loss: 1.039682]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.039601, acc: 2.26%] [G loss: 1.039916]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.039824, acc: 2.27%] [G loss: 1.040137]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.040060, acc: 2.27%] [G loss: 1.040374]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.040298, acc: 2.26%] [G loss: 1.040615]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.040534, acc: 2.26%] [G loss: 1.040847]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.040757, acc: 2.25%] [G loss: 1.041065]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.040975, acc: 2.26%] [G loss: 1.041281]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.041198, acc: 2.25%] [G loss: 1.041506]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.041425, acc: 2.25%] [G loss: 1.041733]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.041646, acc: 2.25%] [G loss: 1.041953]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.041871, acc: 2.25%] [G loss: 1.042181]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.042100, acc: 2.25%] [G loss: 1.042405]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.042320, acc: 2.25%] [G loss: 1.042626]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.042543, acc: 2.25%] [G loss: 1.042841]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.042758, acc: 2.25%] [G loss: 1.043059]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.042981, acc: 2.25%] [G loss: 1.043290]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.043197, acc: 2.25%] [G loss: 1.043497]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.043415, acc: 2.25%] [G loss: 1.043719]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.043631, acc: 2.25%] [G loss: 1.043924]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.043842, acc: 2.25%] [G loss: 1.044141]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.044052, acc: 2.25%] [G loss: 1.044345]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.044259, acc: 2.25%] [G loss: 1.044556]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.044474, acc: 2.25%] [G loss: 1.044770]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.044693, acc: 2.24%] [G loss: 1.044990]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.044909, acc: 2.24%] [G loss: 1.045208]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.045118, acc: 2.24%] [G loss: 1.045408]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.045326, acc: 2.24%] [G loss: 1.045622]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.045537, acc: 2.23%] [G loss: 1.045830]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.045741, acc: 2.23%] [G loss: 1.046030]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.045938, acc: 2.23%] [G loss: 1.046225]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.046143, acc: 2.23%] [G loss: 1.046436]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "******* 0 [D loss: 1.046345, acc: 2.23%] [G loss: 1.046633]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******* \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m [D loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, acc: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m] [G loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, d_loss[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m d_loss[\u001b[38;5;241m1\u001b[39m], g_loss[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     34\u001b[0m     save_imgs(epoch)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m     28\u001b[0m   noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, latent_dim))\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;66;03m# Inverse Y label\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m   g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******* \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m [D loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, acc: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m] [G loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, d_loss[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m d_loss[\u001b[38;5;241m1\u001b[39m], g_loss[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     34\u001b[0m save_imgs(epoch)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:551\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 551\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train(epochs, batch_size = 64, save_interval = 200):\n",
        "  (X_train, _), (_, _) = cifar10.load_data()\n",
        "\n",
        "  # Rescaling the data\n",
        "  X_train = X_train / 127.5 -1.\n",
        "\n",
        "  bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "\n",
        "  # Create Y label for NN\n",
        "  valid = np.ones((batch_size,1))\n",
        "  fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range (epochs) :\n",
        "    for j in range(bat_per_epo) :\n",
        "      #Get Random Batch\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "\n",
        "      # Generate Fakes Images\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      gen_imgs = generator.predict(noise)\n",
        "\n",
        "      # Train Discriminator\n",
        "      d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "      # Inverse Y label\n",
        "      g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "      print(\"******* %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100* d_loss[1], g_loss[0]))\n",
        "    save_imgs(epoch)\n",
        "\n",
        "train(100, batch_size = 64, save_interval = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GS9wDLeRLUOB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n"
          ]
        }
      ],
      "source": [
        "noise = np.random.normal(0, 1, (1,latent_dim))\n",
        "gen_imgs = generator.predict(noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9Rlgu8g9Lik9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd38cad7a60>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gen_imgs = (gen_imgs + 1) / 2.0\n",
        "plt.imshow(gen_imgs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-jSQoN1Azl"
      },
      "source": [
        "### **8) Making GIF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XPShgQpg1EMy"
      },
      "outputs": [],
      "source": [
        "# Display a single image using the epoch number\n",
        "# def display_image(epoch_no):\n",
        "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('generated_images/*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "  if filenames:  # Check if filenames is not empty\n",
        "    image = imageio.imread(filenames[-1])\n",
        "    writer.append_data(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
